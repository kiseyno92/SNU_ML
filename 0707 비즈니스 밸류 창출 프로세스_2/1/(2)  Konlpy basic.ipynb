{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konlpy basic - website(http://konlpy-ko.readthedocs.io/ko/v0.4.3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma  # 꼬꼬마 형태소 분석기 사용\n",
    "\n",
    "kkma = Kkma()\n",
    "text = \"오늘 서울의 날씨는 추워질 전망입니다. 오후 한때 소나기가 올 예정입니다. 아, 오늘은 좀 힘드네요...이런? 난 도대체 뭐지?! 뭐랄까? 뭐라는거니\"\n",
    "\n",
    "sentences = kkma.sentences(text)\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kkma.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_tag = kkma.pos(text)\n",
    "print(pos_tag[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input 형태 = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLTK처럼 내장 데이터를 불러올 수도 있음\n",
    "\n",
    "from konlpy.corpus import kolaw\n",
    "fids = kolaw.fileids()\n",
    "fids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 1 : ko_data에 대해 문장 단위로 나눠보고 Pos tagging 해보기 (시간 체크하여 출력해보기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 실제 data 사용해서 분석해보기 - 인코딩 문제\n",
    "with open('pgh-2015.txt', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#'cp949' codec can't decode byte 0xed in position 6: illegal multibyte sequence 에러인 경우 운영체제의 default 인코딩과 utf-8과 달라서 발생\n",
    "with open('pgh-2015.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 빈 문장 '' 제거\n",
    "sentences = [line for line in lines if line != '']\n",
    "\n",
    "\n",
    "for line in lines[:5]:\n",
    "    if line != '':\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# komoran을 이용한 형태소 분석\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "tagger = Komoran()\n",
    "tags = tagger.pos(sentences[0])\n",
    "\n",
    "print(tags[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagged_sentences = [tagger.pos(sent) for sent in sentences]\n",
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 명사 리스트 만들어 보기\n",
    "noun_list = []\n",
    "\n",
    "for sent in tagged_sentences:    \n",
    "    for word, tag in sent:\n",
    "        if tag in ['NNP', 'NNG']:\n",
    "            noun_list.append(word)\n",
    "noun_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collection library를 이용하여 빈도수 계산하기\n",
    "from collections import Counter\n",
    "\n",
    "noun_counts = Counter(noun_list)\n",
    "noun_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 2 : stop-words 리스트를 만들고 stop-words가 제거된 명사 리스트를 만들어보자\n",
    "### 실습 3 : 만든 명사 리스트를 csv 형태로 저장해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noun_list = []\n",
    "stop_words = ['경제',\"청년\"]\n",
    "for sent in tagged_sentences:    \n",
    "    for word, tag in sent:\n",
    "        if tag in ['NNP', 'NNG']:\n",
    "            if word not in stop_words:\n",
    "                noun_list.append(word)\n",
    "#collecnoun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "noun_counts = collections.Counter(noun_list)\n",
    "noun_counts.most_common(10) # '청년'과 '개혁'이 없어짐을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt # 결과를 시각화 하기 위한 matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# word index 대신 word를 보여주는 그래프\n",
    "freqdist = nltk.FreqDist(noun_counts)\n",
    "freqdist.plot(50)\n",
    "freqdist.plot(50,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 폰트 해결\n",
    "from matplotlib import font_manager, rc\n",
    "font_fname = r'C:\\Windows\\Fonts\\NGULIM.TTF'     # A font of your choice\n",
    "font_name = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freqdist.plot(50)\n",
    "freqdist.plot(50,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unique한 명사 리스트 만들기\n",
    "\n",
    "unique_nouns = set()\n",
    "unique_list = []\n",
    "\n",
    "for sent in tagged_sentences:\n",
    "    for word, tag in sent:\n",
    "        if tag in ['NNP','NNG']:\n",
    "            if word not in unique_list:\n",
    "                unique_list.append(word)\n",
    "                \n",
    "for sent in tagged_sentences:    \n",
    "    for word, tag in sent:\n",
    "        if tag in ['NNP', 'NNG']:\n",
    "            unique_nouns.add(word)\n",
    "\n",
    "unique_nouns = list(unique_nouns)\n",
    "noun_index = {noun: i for i, noun in enumerate(unique_nouns)} # 딕셔너리 형태의 자료구조\n",
    "noun_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장-단어 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 문장 길이 X 명사 종류 matrix 생성\n",
    "occurs = np.zeros([len(tagged_sentences), len(unique_nouns)])\n",
    "np.shape(occurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(tagged_sentences):\n",
    "    for word, tag in sent:\n",
    "        if tag in ['NNP', 'NNG']:\n",
    "            index = noun_index[word]  # 명사가 있으면, 그 명사의 인덱스를 index에 저정\n",
    "            occurs[i][index] = 1  # 문장 i의 index 자리에 1을 채워 넣는다.\n",
    "            \n",
    "occurs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 공존 단어 행렬 계산\n",
    "# i 번째 단어\n",
    "co_occurs = occurs.T.dot(occurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        if (co_occurs[i][j] > 1) & (i>j):\n",
    "            print(unique_nouns[i], unique_nouns[j], co_occurs[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 3 : 새로운 텍스트 데이터에 대해 빈도 그래프, 문장-단어 행렬, 공존 단어 행렬을 계산해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "graph = nx.Graph()\n",
    "\n",
    "for i in range(len(unique_nouns)):\n",
    "    for j in range(i + 1, len(unique_nouns)):\n",
    "        if co_occurs[i][j] > 4:\n",
    "            graph.add_edge(unique_nouns[i], unique_nouns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "krfont = {'family' : 'nanumgothic', 'weight' : 'bold', 'size'   : 10}\n",
    "plt.rc('font',**krfont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "layout = nx.spring_layout(graph, k=.1)\n",
    "nx.draw(graph, pos=layout, with_labels=True,\n",
    "        font_size=20, font_family='Comic Sans MS',\n",
    "        alpha=0.3, node_size=3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python 3에서 networkx 패키지는 한글이 깨지는 에러가 발생"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
