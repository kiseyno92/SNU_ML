{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09_Deep_NN_MNIST_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T06:39:41.364218Z",
     "start_time": "2017-08-04T06:39:41.345636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f069c30e240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch Library\n",
    "import torch\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "torch.manual_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T06:39:42.231086Z",
     "start_time": "2017-08-04T06:39:42.177995Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T06:47:58.535965Z",
     "start_time": "2017-08-04T06:47:58.435212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Linear (784 -> 512)\n",
      "  (1): ReLU ()\n",
      "  (2): Linear (512 -> 512)\n",
      "  (3): ReLU ()\n",
      "  (4): Linear (512 -> 512)\n",
      "  (5): ReLU ()\n",
      "  (6): Linear (512 -> 512)\n",
      "  (7): ReLU ()\n",
      "  (8): Linear (512 -> 256)\n",
      "  (9): ReLU ()\n",
      "  (10): Linear (256 -> 128)\n",
      "  (11): ReLU ()\n",
      "  (12): Linear (128 -> 10)\n",
      "  (13): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Deep Neural Network\n",
    "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
    "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear5 = torch.nn.Linear(512, 256, bias=True)\n",
    "linear6 = torch.nn.Linear(256, 128, bias=True)\n",
    "linear7 = torch.nn.Linear(128, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "#sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "# xavier initializer\n",
    "# torch.nn.init.xavier_uniform(linear1.weight)\n",
    "# torch.nn.init.xavier_uniform(linear2.weight)\n",
    "# torch.nn.init.xavier_uniform(linear3.weight)\n",
    "# torch.nn.init.xavier_uniform(linear4.weight)\n",
    "# torch.nn.init.xavier_uniform(linear5.weight)\n",
    "# torch.nn.init.xavier_uniform(linear6.weight)\n",
    "# torch.nn.init.xavier_uniform(linear7.weight)\n",
    "\n",
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu,\n",
    "                            linear2, relu,\n",
    "                            linear3, relu,\n",
    "                            linear4, relu,\n",
    "                            linear5, relu,\n",
    "                            linear6, relu,\n",
    "                            linear7, relu)   \n",
    "model.cuda()\n",
    "\n",
    "#model.load_state_dict(torch.load('DNN.pkl'))  # Load the Trained Model\n",
    "\n",
    "print(model)\n",
    "# print('Weight matrix: ', model.weight.data)\n",
    "# print('bias vector: ', model.bias.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T06:50:49.107404Z",
     "start_time": "2017-08-04T06:48:03.383303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.556651652\n",
      "[Epoch:    2] cost = 0.343746841\n",
      "[Epoch:    3] cost = 0.311643869\n",
      "[Epoch:    4] cost = 0.291136444\n",
      "[Epoch:    5] cost = 0.283704191\n",
      "[Epoch:    6] cost = 0.272350699\n",
      "[Epoch:    7] cost = 0.268389672\n",
      "[Epoch:    8] cost = 0.262971342\n",
      "[Epoch:    9] cost = 0.265035629\n",
      "[Epoch:   10] cost = 0.255123436\n",
      "[Epoch:   11] cost = 0.251195043\n",
      "[Epoch:   12] cost = 0.251167089\n",
      "[Epoch:   13] cost = 0.24736838\n",
      "[Epoch:   14] cost = 0.251571566\n",
      "[Epoch:   15] cost = 0.246433824\n",
      "[Epoch:   16] cost = 0.245539501\n",
      "[Epoch:   17] cost = 0.243946388\n",
      "[Epoch:   18] cost = 0.243684247\n",
      "[Epoch:   19] cost = 0.24546963\n",
      "[Epoch:   20] cost = 0.241581306\n",
      "[Epoch:   21] cost = 0.241334602\n",
      "[Epoch:   22] cost = 0.239114419\n",
      "[Epoch:   23] cost = 0.243339986\n",
      "[Epoch:   24] cost = 0.241198525\n",
      "[Epoch:   25] cost = 0.237277612\n",
      "[Epoch:   26] cost = 0.241510257\n",
      "[Epoch:   27] cost = 0.239520103\n",
      "[Epoch:   28] cost = 0.238840908\n",
      "[Epoch:   29] cost = 0.23869592\n",
      "[Epoch:   30] cost = 0.23714681\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# Softmax 함수가 Cost를 계산할 때 내장되어 있다.\n",
    "cost_func = torch.nn.CrossEntropyLoss()   \n",
    "\n",
    "# Hyper-parameters\n",
    "learning_rate = 0.001 \n",
    "training_epochs = 30\n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(mnist_train) // batch_size\n",
    "\n",
    "    for i, (batch_images, batch_labels) in enumerate(data_loader):\n",
    "        \n",
    "        # 이미지를 [batch_size x 784] size 행렬로 변환\n",
    "        \n",
    "        X = Variable(batch_images.view(-1, 28 * 28)).cuda()\n",
    "        Y = Variable(batch_labels).cuda()  # label is not one-hot encoded\n",
    "\n",
    "        optimizer.zero_grad()             # Zero Gradient Container\n",
    "        Y_prediction = model(X)           # Forward Propagation\n",
    "        cost = cost_func(Y_prediction, Y) # compute cost\n",
    "        cost.backward()                   # compute gradient\n",
    "        optimizer.step()                  # gradient update\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost.data[0]))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "torch.save(model.state_dict(), 'DNN.pkl')  # Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set을 이용한 모형 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T06:57:57.681213Z",
     "start_time": "2017-08-04T06:57:45.301222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 88 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in mnist_test:\n",
    "    images = Variable(images.view(-1, 28*28)).cuda()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T06:57:58.752269Z",
     "start_time": "2017-08-04T06:57:58.458742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  \n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "Prediction:  \n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06b1056748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, len(mnist_test) - 1)\n",
    "X_single_data = Variable(mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float()).cuda()\n",
    "Y_single_data = Variable(mnist_test.test_labels[r:r + 1]).cuda()\n",
    "\n",
    "single_prediction = model(X_single_data)\n",
    "\n",
    "print(\"Label: \", Y_single_data.data)\n",
    "print(\"Prediction: \", torch.max(single_prediction.data, 1)[1])\n",
    "\n",
    "plt.imshow(X_single_data.cpu().data.view(28,28).numpy() , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
